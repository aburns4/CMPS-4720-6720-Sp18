{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Andrea Burns\n",
    "#Data Reader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read each data frame in from my excel sheets\n",
    "xls = pd.ExcelFile('DataDownload.xls')\n",
    "df1 = pd.read_excel(xls, 'ACCESS')\n",
    "df2 = pd.read_excel(xls, 'STORES')\n",
    "df3 = pd.read_excel(xls, 'RESTAURANTS')\n",
    "df4 = pd.read_excel(xls, 'ASSISTANCE')\n",
    "df5 = pd.read_excel(xls, 'INSECURITY')\n",
    "df6 = pd.read_excel(xls, 'PRICES_TAXES')\n",
    "df7 = pd.read_excel(xls, 'LOCAL')\n",
    "df8 = pd.read_excel(xls, 'HEALTH')\n",
    "df9 = pd.read_excel(xls, 'SOCIOECONOMIC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#these will be my output space; I'll try to predict these features\n",
    "diabetes08 = df8['PCT_DIABETES_ADULTS08'].as_matrix()\n",
    "diabetes13 = df8['PCT_DIABETES_ADULTS13'].as_matrix()\n",
    "obesity08 = df8['PCT_OBESE_ADULTS08'].as_matrix()\n",
    "obesity13 = df8['PCT_OBESE_ADULTS13'].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#remove my Y from the feature space to train on\n",
    "df8 = df8.drop('PCT_DIABETES_ADULTS08', 1)\n",
    "df8 = df8.drop('PCT_DIABETES_ADULTS13', 1)\n",
    "df8 = df8.drop('PCT_OBESE_ADULTS08', 1)\n",
    "df8 = df8.drop('PCT_OBESE_ADULTS13', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alldata = [df1,df2,df3,df4,df5,df6,df7,df8,df9] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#formatting all instances\n",
    "X = []\n",
    "i = 0\n",
    "for i in range(0,3143):\n",
    "    current_row = []\n",
    "    for frame in alldata:\n",
    "        mat = frame.as_matrix()\n",
    "        current_row.append(mat[i][3:])\n",
    "    X.append(list(itertools.chain(*current_row)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#some features are missing data for specific instances, so I want to find them and deal with them\n",
    "missing = np.argwhere(np.isnan(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1, 2, 4, 6, 7, 9, 11, 12, 14, 15, 16, 18, 19, 21, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 43, 46, 49, 52, 55, 58, 61, 64, 67, 69, 70, 73, 76, 79, 82, 85, 88, 93, 94, 95, 99, 100, 101, 115, 116, 117, 118, 125, 126, 127, 128, 129, 130, 146, 147, 148, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 169, 170, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 254, 257, 266, 267, 269, 272}\n"
     ]
    }
   ],
   "source": [
    "feats = []\n",
    "for i in range(0,len(missing)):\n",
    "    feats.append(missing[i][1])\n",
    "print(set(feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#these are two of the ~10 categorical features. Only these two have missing features\n",
    "#since they are 0 or 1 binary classes, it doesn't make sense to replace NaN values with the mean of the column\n",
    "#so instead I replace it will -1 as a \"missing\" class\n",
    "for i in range(0,len(missing)):\n",
    "    if missing[i][1] == 249:\n",
    "        X[missing[i][0]][249] = -1\n",
    "    elif missing[i][1] == 250:\n",
    "        X[missing[i][0]][250] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#all other features are continuous so I can impute NaN values with the mean of the feature!\n",
    "from sklearn.preprocessing import Imputer\n",
    "# missing_values is the value of your placeholder, strategy is if you'd like mean, median or mode, and axis=0 means it calculates the imputation based on the other feature values for that sample\n",
    "imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "imp.fit(X)\n",
    "inputspace = imp.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I didn't previously realize that the diabetes and obesity vectors had Nan \n",
    "#now fixing it similarly with the below cells, only a few were missing (3 or 4)\n",
    "imp2 = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "diabetes08=diabetes08.reshape(-1,1)\n",
    "imp2.fit(diabetes08)\n",
    "outputspace1 = imp2.transform(diabetes08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imp3 = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "diabetes13=diabetes13.reshape(-1,1)\n",
    "imp3.fit(diabetes13)\n",
    "outputspace2 = imp3.transform(diabetes13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imp4 = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "obesity08=obesity08.reshape(-1,1)\n",
    "imp4.fit(obesity08)\n",
    "outputspace3 = imp4.transform(obesity08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imp5 = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "obesity13=obesity13.reshape(-1,1)\n",
    "imp5.fit(obesity13)\n",
    "outputspace4 = imp5.transform(obesity13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.preprocessing as prep\n",
    "inputspace = prep.scale(inputspace)\n",
    "\n",
    "#making different classifiers to try to predict the four rates \n",
    "X_train, X_test, y_train, y_test = train_test_split(inputspace,outputspace1.ravel(), test_size=0.1, random_state=42)\n",
    "diab8clf = SVR(C=1.0, epsilon=0.2)\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(inputspace,outputspace2.ravel(), test_size=0.1, random_state=42)\n",
    "diab13clf = SVR(C=1.0, epsilon=0.2)\n",
    "\n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(inputspace,outputspace3.ravel(), test_size=0.1, random_state=42)\n",
    "obes8clf = SVR(C=1.0, epsilon=0.2)\n",
    "\n",
    "X_train4, X_test4, y_train4, y_test4 = train_test_split(inputspace,outputspace4.ravel(), test_size=0.1, random_state=42)\n",
    "obes13clf = SVR(C=1.0, epsilon=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=1.0, cache_size=200, coef0=0.0, degree=3, epsilon=0.2, gamma='auto',\n",
       "  kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fitting train data with SVM model for regression, as I am predicting the diabetes or obesity rates\n",
    "#which are continuous values\n",
    "diab8clf.fit(X_train,y_train)\n",
    "diab13clf.fit(X_train2,y_train2)\n",
    "obes8clf.fit(X_train3,y_train3)\n",
    "obes13clf.fit(X_train4,y_train4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test portion \n",
    "diabetes8pred = diab8clf.predict(X_test)\n",
    "diabetes13pred = diab13clf.predict(X_test2)\n",
    "obesity8pred = obes8clf.predict(X_test3)\n",
    "obesity13pred = obes13clf.predict(X_test4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson Coefficient and MSE for Diabetes Prediction in 2008\n",
      "(0.9119756128617906, 3.7663255632562475e-123)\n",
      "0.82236275945728\n",
      "\n",
      "Pearson Coefficient and MSE for Diabetes Prediction in 2013\n",
      "(0.8740210255469344, 3.960268806775074e-100)\n",
      "1.5043250592260557\n",
      "\n",
      "Pearson Coefficient and MSE for Obesity Prediction in 2008\n",
      "(0.8363386149441886, 1.052059362694424e-83)\n",
      "4.542912274967804\n",
      "\n",
      "Pearson Coefficient and MSE for Obesity Prediction in 2013\n",
      "(0.8165881401494428, 1.0994118503700413e-76)\n",
      "7.158954486310911\n"
     ]
    }
   ],
   "source": [
    "#these are two standard performance metrics for regression, printing them for each\n",
    "#mean squared error has been shown in class, kind of like avg. distance btw output and target values\n",
    "#pearson coefficient is a statistic used to show the strength of a linear relationship\n",
    "#best pearson value possible is -1 or 1 (perfectly negative or positive relationship)\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.metrics import mean_squared_error\n",
    "print('Pearson Coefficient and MSE for Diabetes Prediction in 2008')\n",
    "print(pearsonr(np.asarray(y_test).ravel(),diabetes8pred.ravel()))\n",
    "mean_sqr1 = mean_squared_error(diabetes8pred, y_test)\n",
    "print(mean_sqr1)\n",
    "print()\n",
    "\n",
    "print('Pearson Coefficient and MSE for Diabetes Prediction in 2013')\n",
    "print(pearsonr(np.asarray(y_test2).ravel(),diabetes13pred.ravel()))\n",
    "mean_sqr2 = mean_squared_error(diabetes13pred, y_test2)\n",
    "print(mean_sqr2)\n",
    "print()\n",
    "\n",
    "print('Pearson Coefficient and MSE for Obesity Prediction in 2008')\n",
    "print(pearsonr(np.asarray(y_test3).ravel(),obesity8pred.ravel()))\n",
    "mean_sqr3 = mean_squared_error(obesity8pred, y_test3)\n",
    "print(mean_sqr3)\n",
    "print()\n",
    "\n",
    "print('Pearson Coefficient and MSE for Obesity Prediction in 2013')\n",
    "print(pearsonr(np.asarray(y_test4).ravel(),obesity13pred.ravel()))\n",
    "mean_sqr4 = mean_squared_error(obesity13pred, y_test4)\n",
    "print(mean_sqr4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
